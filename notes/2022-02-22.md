
## Learning
- [x] [Scrapy for Beginners - A Complete How To Example Web Scraping Project](https://www.youtube.com/watch?v=s4jtkzHhLzY&t=377s)
- [ ] [Intro To Web Crawlers & Scraping With Scrapy](https://www.youtube.com/watch?v=ALizgnSFTwQ)
- [x] [Beautiful Soup 4 Tutorial #1 - Web Scraping With Python](https://www.youtube.com/watch?v=gRLHr664tXA)
- [x] [How To Crawl A Web Page with Scrapy and Python 3](https://www.digitalocean.com/community/tutorials/how-to-crawl-a-web-page-with-scrapy-and-python-3)

## Code
- validity-checks (required modules)
- constants
  - doc-regex
  - dir-regex
  - temp-control-options (delete-in-progress, delete-on-complete, delete-on-exit, no-delete)
- generate `input.csv` (manual, in excel)
- make `dir_links.csv` from `input.csv`
- make `doc_links.csv` from `dir_links.csv`
  - get 10-k link from directory page (scrapy)
  - fix bad links
    - Bad: `https://www.sec.gov/ix?doc=/Archives/edgar/data/1555280/000155528021000098/zts-20201231.htm`
    - Fix: `https://www.sec.gov/Archives/edgar/data/1555280/000155528021000098/zts-20201231.htm`
- download page
  - (and delete, depending on options)
- strip html from page
- search page
  - on `divers` found, grab leading 50 characters and trailing 50 characters (regex)
  - save to `stats.csv`
- save to `original.xlsx`
  - also include link to 10-K form
- cleanup (if set in options)

## Folder Layout
- `original.xlsx` (whatever file all this data came from)
- `input.csv` (direct export from excel) (user generates this)
- `temp/` (all intermediary generated files) (we generate this if not present)
  - `dir_links.csv` (`row_id,dir_link`)
  - `plain_links.csv` (`row_id,doc_link`)
  - `full_pages/`
    - `zts-20201231.htm`
  - `bare_pages/`
    - `zts-20201231.htm`
- `stats.csv` (final outputted file) (`row_id,sentence_count,sentences`)
- `final.xlsx` (optional (for the time being)) (copy and modify `original.xlsx` with the new info)

## Annoying Response
```
U.S. Securities and Exchange Commission

Your Request Originates from an Undeclared Automated Tool
To allow for equitable access to all users, SEC reserves the right to limit requests originating from undeclared automated tools. Your request has been identified as part of a network of automated tools outside of the acceptable policy and will be managed until action is taken to declare your traffic.
Please declare your traffic by updating your user agent to include company specific information.
For best practices on efficiently downloading information from SEC.gov, including the latest EDGAR filings, visit sec.gov/developer. You can also sign up for email updates on the SEC open data program, including best practices that make it more efficient to download data, and SEC.gov enhancements that may impact scripted downloading processes. For more information, contact opendata@sec.gov.
For more information, please see the SECâs Web Site Privacy and Security Policy. Thank you for your interest in the U.S. Securities and Exchange Commission.
Reference ID: 0.37333217.1645591190.2061b5e0

More Information
Internet Security Policy
By using this site, you are agreeing to security monitoring and auditing. For security purposes, and to ensure that the public service remains available to users, this government computer system employs programs to monitor network traffic to identify unauthorized attempts to upload or change information or to otherwise cause damage, including attempts to deny service to users.
Unauthorized attempts to upload information and/or change information on any portion of this site are strictly prohibited and are subject to prosecution under the Computer Fraud and Abuse Act of 1986 and the National Information Infrastructure Protection Act of 1996 (see Title 18 U.S.C. Â§Â§ 1001 and 1030).
To ensure our website performs well for all users, the SEC monitors the frequency of requests for SEC.gov content to ensure automated searches do not impact the ability of others to access SEC.gov content. We reserve the right to block IP addresses that submit excessive requests.  Current guidelines limit users to a total of no more than 10 requests per second, regardless of the number of machines used to submit requests.
If a user or application submits more than 10 requests per second, further requests from the IP address(es) may be limited for a brief period. Once the rate of requests has dropped below the threshold for 
10 minutes, the user may resume accessing content on SEC.gov. This SEC practice is designed to limit excessive automated searches on SEC.gov and is not intended or expected to impact individuals browsing the SEC.gov website.
Note that this policy may change as the SEC manages SEC.gov to ensure that the website performs efficiently and remains available to all users.


Note: We do not offer technical support for developing or debugging scripted downloading processes.
```

## Example Stats File 1
```csv
row_id,sentence_count,sentences
1,0,""
2,1,"We value diversity at XBO Incorporated."
3,2,"Diversity?\nWhy would we want diversity at Skynet?"
4,3,"Intradus Corporate successfully divested itself of 3 million liabilities last year alone.\nLong term strategies include diversification of assets, market analysis and research, diversity and equity studies, and other ancillary pursuits."
5,4,"Diversity studies last year indicate a lack of human life forms in active employment at this company.\nDiverse investment strategies have been considered.\nDiversity programs improved human-computer relations by 300%.\nDiversity efforts at Ants Inc are likely to continue into the future."
6,5,"Diversity of assets were expanded in the last fiscal year following our general plan of diversification enhancement as laid out in section 12 of DBB's 2020 Corporate Plan.\nDiverse and talented individuals are sought to improve foreign relations.\nDiversity of mind can often be accompanied by diversity of circumstance."
```
- Ok, so Excel 2010 does not recognize `\n` ("Newline Escape Characters") as newlines
- Instead, must literally embed a newline character into the text (breaking the CSV)
- This is allowed, though it does make parsing ugly
- So I will treat this as a final export step
- See [Example Stats File 2](#example-stats-file-2) for actual result

## Example Stats File 2
```csv
row_id,sentence_count,sentences
1,0,""
2,1,"We value diversity at XBO Incorporated."
3,2,"Diversity?
Why would we want diversity at Skynet?"
4,3,"Intradus Corporate successfully divested itself of 3 million liabilities last year alone.
Long term strategies include diversification of assets, market analysis and research, diversity and equity studies, and other ancillary pursuits."
5,4,"Diversity studies last year indicate a lack of human life forms in active employment at this company.
Diverse investment strategies have been considered.
Diversity programs improved human-computer relations by 300%.
Diversity efforts at Ants Inc are likely to continue into the future."
6,5,"Diversity of assets were expanded in the last fiscal year following our general plan of diversification enhancement as laid out in section 12 of DBB's 2020 Corporate Plan.
Diverse and talented individuals are sought to improve foreign relations.
Diversity of mind can often be accompanied by diversity of circumstance."
```

## Using EDGAR
- Take last row in sheet as example
- `337,013721,188754,0001555280,Zoetis Inc.,...,https://www.sec.gov/Archives/edgar/data/edgar/data/1555280/0001555280-21-000098-index.htm,...`
- According to https://www.sec.gov/edgar/sec-api-documentation
- Should have data accessible at https://data.sec.gov/submissions/CIK0001555280.json
- Only the "XBRL" data itself is accessible via this endpoint (not the actual 10-K document contents itself)
- > ...the XBRL data from financial statements (forms 10-Q, 10-K,8-K, 20-F, 40-F, 6-K, and their variants).
- There appears to be a "full text search"
- [Example searching for "diversity" in "10-K" forms for "All Companies"](https://www.sec.gov/edgar/search/#/q=diversity&category=custom&forms=10-K)
- Does not appear to offer any export/citation options

## Resources
- [x] [Importing CSV with line breaks](https://answers.microsoft.com/en-us/msoffice/forum/all/importing-csv-with-line-breaks/a989987f-e12f-43f9-8ea5-79543012457e)
- [x] **[Importing CSV with line breaks in Excel 2007](https://stackoverflow.com/questions/2668678/importing-csv-with-line-breaks-in-excel-2007)**
- [x] [Openpyxl auto-height row](https://stackoverflow.com/questions/37891149/openpyxl-auto-height-row)
- [x] [openpyxl - adjust column width size](https://stackoverflow.com/questions/13197574/openpyxl-adjust-column-width-size)
- [x] **[Python | Adjusting rows and columns of an excel file using openpyxl module](https://www.geeksforgeeks.org/python-adjusting-rows-and-columns-of-an-excel-file-using-openpyxl-module/)**
- [x] **[How can I get all the plain text from a website with Scrapy?](https://stackoverflow.com/questions/23156780/how-can-i-get-all-the-plain-text-from-a-website-with-scrapy)**
- [x] [Writing multi-line strings into cells using openpyxl](https://stackoverflow.com/questions/15370432/writing-multi-line-strings-into-cells-using-openpyxl)
- [x] [Setting styles in Openpyxl](https://stackoverflow.com/questions/8440284/setting-styles-in-openpyxl)
- [x] [Working with styles](https://openpyxl.readthedocs.io/en/stable/styles.html)
- [x] [How to find the last row in a column using openpyxl normal workbook?](https://stackoverflow.com/questions/33541692/how-to-find-the-last-row-in-a-column-using-openpyxl-normal-workbook)
- [x] [Get html using Python requests?](https://stackoverflow.com/questions/27803503/get-html-using-python-requests)
- [x] [Sending "User-agent" using Requests library in Python](https://stackoverflow.com/questions/10606133/sending-user-agent-using-requests-library-in-python)
- [ ] [What's a good rate limiting algorithm?](https://stackoverflow.com/questions/667508/whats-a-good-rate-limiting-algorithm?noredirect=1&lq=1)
- [ ] [RateLimiter Simple Python module providing rate limiting](https://github.com/RazerM/ratelimiter)
- [x] [Rate Limiting with Python](https://akshayranganath.github.io/Rate-Limiting-With-Python/)
- [ ] [Python API Rate Limiting - How to Limit API Calls Globally](https://stackoverflow.com/questions/40748687/python-api-rate-limiting-how-to-limit-api-calls-globally)
- [x] [How to find all occurrences of a substring?](https://stackoverflow.com/questions/4664850/how-to-find-all-occurrences-of-a-substring)

## SEC Resources
- [ ] **[How to Web Scrape the SEC | Part 1](https://www.youtube.com/watch?v=-7I7OAC6ih8)**
- [ ] [A simple python library that allows for easy access of the SEC website so that someone can parse filings, collect data, and query documents.](https://github.com/areed1192/python-sec)
- [ ] [sigma_coding_youtube/python/python-finance/sec-web-scraping](https://github.com/areed1192/sigma_coding_youtube/tree/master/python/python-finance/sec-web-scraping)
  - Very interesting examples, even includes the "10K" Forms
- [ ] [curl-impersonate: A special compilation of curl that makes it impersonate Chrome & Firefox](https://github.com/lwthiker/curl-impersonate)
- [ ] [Developer Resources](https://www.sec.gov/developer)
- [ ] [Accessing EDGAR Data](https://www.sec.gov/os/accessing-edgar-data)
- [x] [ EDGAR Application Programming Interfaces](https://www.sec.gov/edgar/sec-api-documentation)

## Misc Resources
- [ ] [StyleFrame A library that wraps pandas and openpyxl and allows easy styling of dataframes in excel](https://github.com/DeepSpace2/StyleFrame)
- [x] [Read and Write CSV files including unicode with Python 2.7](https://stackoverflow.com/questions/17245415/read-and-write-csv-files-including-unicode-with-python-2-7) (Unnecessary in Python 3)
- [x] [Writing CSV files in Python](https://www.geeksforgeeks.org/writing-csv-files-in-python/)
- [x] [Pythonically add header to a csv file](https://stackoverflow.com/questions/20347766/pythonically-add-header-to-a-csv-file)
- [x] [CSV in Python adding an extra carriage return, on Windows](https://stackoverflow.com/questions/3191528/csv-in-python-adding-an-extra-carriage-return-on-windows)
- [x] [How can I safely create a nested directory?](https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory)
- [x] [How to check if a module is installed in Python and, if not, install it within the code?](https://stackoverflow.com/questions/44210656/how-to-check-if-a-module-is-installed-in-python-and-if-not-install-it-within-t)
- [x] [Scrapy at a glance](https://docs.scrapy.org/en/latest/intro/overview.html)
- [x] [Command line tool](https://docs.scrapy.org/en/latest/topics/commands.html)
- [x] [Scrapy: How to set scrapy start_urls from a setting file?](https://stackoverflow.com/questions/42530218/scrapy-how-to-set-scrapy-start-urls-from-a-setting-file)
- [x] [Download a full page with scrapy](https://stackoverflow.com/questions/38233614/download-a-full-page-with-scrapy)
- [x] [Needed a possibility to pass start_urls parameter in constructor #1823 ](https://github.com/scrapy/scrapy/issues/1823)
- [x] [dynamic start_urls in scrapy](https://stackoverflow.com/questions/8798235/dynamic-start-urls-in-scrapy)
- [x] [How to generate the start_urls dynamically in crawling?](https://stackoverflow.com/questions/9322219/how-to-generate-the-start-urls-dynamically-in-crawling)
- [ ] [How to run Scrapy from within a Python script](https://stackoverflow.com/questions/13437402/how-to-run-scrapy-from-within-a-python-script)
- [ ] [Run Scrapy from a script](https://docs.scrapy.org/en/latest/topics/practices.html)
- [ ] [How to Run Scrapy From a Script](https://towardsdatascience.com/how-to-run-scrapy-from-a-script-ff07fd6b792b)
- [x] [Automatically create requirements.txt](https://stackoverflow.com/questions/31684375/automatically-create-requirements-txt)
- [x] [pipreqs - Generate pip requirements.txt file based on imports of any project. Looking for maintainers to move this project forward.](https://github.com/bndr/pipreqs)
- [x] [Read JSON file using Python](https://www.geeksforgeeks.org/read-json-file-using-python/)
- [x] [How do I find the maximum of 2 numbers?](https://stackoverflow.com/questions/3357369/how-do-i-find-the-maximum-of-2-numbers)
